{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ec19ca-81bd-42bb-aab2-be9e34430009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "No normalization for NumAmideBonds. Feature removed!\n",
      "No normalization for NumAtomStereoCenters. Feature removed!\n",
      "No normalization for NumBridgeheadAtoms. Feature removed!\n",
      "No normalization for NumHeterocycles. Feature removed!\n",
      "No normalization for NumSpiroAtoms. Feature removed!\n",
      "No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
      "No normalization for Phi. Feature removed!\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (C:\\Users\\yyyyx\\miniconda3\\envs\\deepchem\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "from deepchem.feat.graph_data import GraphData\n",
    "from deepchem.feat import MolGraphConvFeaturizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from deepchem.models.torch_models import TorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09e3fdff-e864-418f-8e4d-823bb0806931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28833125-d217-45d5-88ec-5affddc83970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./AqsolDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6869c4-9ac3-4b17-8aa4-dbdf0bb8c77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Drug_ID</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCC[N+](C)(C)C.[Br-]</td>\n",
       "      <td>-3.616127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>O=Cc1ccc(Cl)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n",
       "      <td>CC(c1ccccc1)c1cc(C(=O)[O-])c(O)c(C(C)c2ccccc2)...</td>\n",
       "      <td>-3.924409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>9977</td>\n",
       "      <td>tetracaine</td>\n",
       "      <td>CCCCNc1ccc(C(=O)OCCN(C)C)cc1</td>\n",
       "      <td>-3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>9978</td>\n",
       "      <td>tetracycline</td>\n",
       "      <td>CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C...</td>\n",
       "      <td>-2.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>9979</td>\n",
       "      <td>thymol</td>\n",
       "      <td>Cc1ccc(C(C)C)c(O)c1</td>\n",
       "      <td>-2.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>9980</td>\n",
       "      <td>verapamil</td>\n",
       "      <td>COc1ccc(CCN(C)CCCC(C#N)(c2ccc(OC)c(OC)c2)C(C)C...</td>\n",
       "      <td>-3.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>9981</td>\n",
       "      <td>warfarin</td>\n",
       "      <td>CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O</td>\n",
       "      <td>-4.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9982 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                            Drug_ID  \\\n",
       "0              0         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1              1                           Benzo[cd]indol-2(1H)-one   \n",
       "2              2                               4-chlorobenzaldehyde   \n",
       "3              3  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
       "4              4  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "...          ...                                                ...   \n",
       "9977        9977                                         tetracaine   \n",
       "9978        9978                                       tetracycline   \n",
       "9979        9979                                             thymol   \n",
       "9980        9980                                          verapamil   \n",
       "9981        9981                                           warfarin   \n",
       "\n",
       "                                                   Drug         Y  \n",
       "0                   CCCCCCCCCCCCCCCCCC[N+](C)(C)C.[Br-] -3.616127  \n",
       "1                                  O=C1Nc2cccc3cccc1c23 -3.254767  \n",
       "2                                       O=Cc1ccc(Cl)cc1 -2.177078  \n",
       "3     CC(c1ccccc1)c1cc(C(=O)[O-])c(O)c(C(C)c2ccccc2)... -3.924409  \n",
       "4     c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO... -4.662065  \n",
       "...                                                 ...       ...  \n",
       "9977                       CCCCNc1ccc(C(=O)OCCN(C)C)cc1 -3.010000  \n",
       "9978  CN(C)[C@@H]1C(O)=C(C(N)=O)C(=O)[C@@]2(O)C(O)=C... -2.930000  \n",
       "9979                                Cc1ccc(C(C)C)c(O)c1 -2.190000  \n",
       "9980  COc1ccc(CCN(C)CCCC(C#N)(c2ccc(OC)c(OC)c2)C(C)C... -3.980000  \n",
       "9981              CC(=O)CC(c1ccccc1)c1c(O)c2ccccc2oc1=O -4.780000  \n",
       "\n",
       "[9982 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20454eb-293b-4638-a605-9070ef24e9d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 4792, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(class RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True, bool includeAtomMaps=True, bool includeChiralPresence=False)\n",
      "Failed to featurize datapoint 5043, None. Appending empty array\n",
      "Exception message: Python argument types in\n",
      "    rdkit.Chem.rdmolfiles.CanonicalRankAtoms(NoneType)\n",
      "did not match C++ signature:\n",
      "    CanonicalRankAtoms(class RDKit::ROMol mol, bool breakTies=True, bool includeChirality=True, bool includeIsotopes=True, bool includeAtomMaps=True, bool includeChiralPresence=False)\n",
      "Exception message: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9982,) + inhomogeneous part.\n"
     ]
    }
   ],
   "source": [
    "# 1. SMILES에서 그래프 형식으로 변환\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "features = featurizer.featurize(df[\"Drug\"])  # Smiles 컬럼에서 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f96ee-6dbf-4e89-a8ce-c949e197e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphConv\n",
    "features = featurizer.featurize()\n",
    "(df[\"Drug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2149f8d1-d38c-4427-be89-f5d0fa447702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<deepchem.feat.mol_graphs.ConvMol object at 0x0000022523D36B20>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x0000022523D363D0>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x0000022523D36F70>,\n",
       "       ...,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x000002252CCB08B0>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x000002252CCB07C0>,\n",
       "       <deepchem.feat.mol_graphs.ConvMol object at 0x000002252CCB0910>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63176f01-8bbb-495a-98c4-7812ccef7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 레이블 설정 (pIC50)\n",
    "labels = df[\"Y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98b7b752-7882-4403-aba3-ed30ab465c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 가중치 (필요시 기본값으로 1 설정)\n",
    "weights = None  # 기본적으로 None으로 설정. 커스텀 가중치가 있으면 지정.\n",
    "\n",
    "# 4. 데이터셋 생성\n",
    "dataset = dc.data.NumpyDataset(X=features, y=labels, w=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cb933fa-9bf4-4248-9614-81c44a85a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid indices: [4792, 5043]\n"
     ]
    }
   ],
   "source": [
    "invalid_indices = []\n",
    "for i, x_item in enumerate(dataset.X):\n",
    "    # 예: x_item 이 비어 있거나, 그래프가 아닌 ndarray인 경우 invalid 처리\n",
    "    if (isinstance(x_item, np.ndarray) and len(x_item) == 0):\n",
    "        invalid_indices.append(i)\n",
    "\n",
    "print(\"Invalid indices:\", invalid_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a6082ef-6240-4430-849f-7d5ae3f6e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import numpy as np\n",
    "\n",
    "# 유효한 인덱스를 골라낸다\n",
    "valid_indices = [\n",
    "    i for i in range(len(dataset.X)) if i not in invalid_indices\n",
    "]\n",
    "\n",
    "# 유효한 X, y, w, ids만 추출\n",
    "filtered_X   = [dataset.X[i] for i in valid_indices]\n",
    "filtered_y   = [dataset.y[i] for i in valid_indices]\n",
    "filtered_w   = [dataset.w[i] for i in valid_indices]\n",
    "filtered_ids = [dataset.ids[i] for i in valid_indices]\n",
    "\n",
    "# 새롭게 NumpyDataset 생성\n",
    "new_dataset = dc.data.NumpyDataset(\n",
    "    X=filtered_X,\n",
    "    y=filtered_y,\n",
    "    w=filtered_w,\n",
    "    ids=filtered_ids\n",
    ")\n",
    "\n",
    "# 이제 new_test_dataset을 대신 사용하면 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cb67662-97a4-40e6-abc5-d61da1738bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NumpyDataset X.shape: (9982,), y.shape: (9982,), w.shape: (9982,), task_names: [0]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "356fa1aa-2171-48b1-b039-86fe5b8b5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_pytorch = new_dataset.make_pytorch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21870a5c-2b14-40d9-8e35-ae908f24886f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type '_TorchNumpyDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 데이터셋 확인\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of samples in dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_dataset_pytorch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_dataset\u001b[38;5;241m.\u001b[39mX[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnode_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_dataset\u001b[38;5;241m.\u001b[39mX[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_dataset\u001b[38;5;241m.\u001b[39my[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type '_TorchNumpyDataset' has no len()"
     ]
    }
   ],
   "source": [
    "# 데이터셋 확인\n",
    "print(f\"Number of samples in dataset: {len(new_dataset)}\")\n",
    "print(f\"Feature shape: {new_dataset.X[0].node_features.shape[0]} nodes, {new_dataset.X[0].edge_index.shape[1]} edges\")\n",
    "print(f\"First label: {new_dataset.y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67c4477a-cb2c-4046-be81-4540604a190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 7984\n",
      "Validation dataset size: 998\n",
      "Test dataset size: 998\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 Train/Validation/Test로 나누기\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(new_dataset)\n",
    "\n",
    "# 확인\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e90e95b4-fd2a-45b0-b127-b689a0eb8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.make_pytorch_dataset\n",
    "test_dataset = test_dataset.make_pytorch_dataset\n",
    "valid_dataset = valid_dataset.make_pytorch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48a3f6cb-630d-4c8d-9c7d-aa909ddd070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU 또는 CPU 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4afad1ce-1b48-4e3b-8ad1-9dacd5a79d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 목록 정의\n",
    "param_grid = {\n",
    "    'graph_conv_layers': [[64, 64], [128, 128], [64, 128, 64]],\n",
    "    'dense_layer_size': [128, 256],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4],\n",
    "    'batch_size': [128]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889efbd1-97de-4aa3-8b98-b2d9ba99d3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress: 100%|███████████████████████████████████████████████████████████| 36/36 [00:00<00:00, 461.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running combination 1/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 2/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 3/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 4/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 5/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 6/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 7/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 8/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 9/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 10/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 11/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 12/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 13/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 14/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 15/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 16/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 17/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 18/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 19/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 20/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 21/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 22/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 23/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 24/36:\n",
      "graph_conv_layers: [128, 128], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 25/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 26/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 27/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 28/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 29/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 30/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 128, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 31/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 32/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 33/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.2, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 34/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 35/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0005, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "\n",
      "Running combination 36/36:\n",
      "graph_conv_layers: [64, 128, 64], dense_layer_size: 256, dropout: 0.3, learning_rate: 0.0001, batch_size: 128\n",
      "Error during training: 'Adam' object has no attribute '_create_pytorch_optimizer'\n",
      "No valid results collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import deepchem as dc\n",
    "from deepchem.models.torch_models import TorchModel\n",
    "\n",
    "# PyTorch 기반 GCN 모델 정의\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(hidden_dims)):\n",
    "            in_dim = input_dim if i == 0 else hidden_dims[i - 1]\n",
    "            layers.append(nn.Linear(in_dim, hidden_dims[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(hidden_dims[-1], output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# 하이퍼파라미터 조합 반복\n",
    "combinations = list(product(\n",
    "    param_grid['graph_conv_layers'],\n",
    "    param_grid['dense_layer_size'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['batch_size']\n",
    "))\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "results = []\n",
    "\n",
    "for i, (graph_conv_layers, dense_layer_size, dropout, learning_rate, batch_size) in enumerate(tqdm(combinations, desc=\"Grid Search Progress\")):\n",
    "    print(f\"\\nRunning combination {i+1}/{len(combinations)}:\")\n",
    "    print(f\"graph_conv_layers: {graph_conv_layers}, dense_layer_size: {dense_layer_size}, dropout: {dropout}, learning_rate: {learning_rate}, batch_size: {batch_size}\")\n",
    "\n",
    "    # PyTorch 모델 초기화\n",
    "    input_dim = 75  # ConvMolFeaturizer의 기본 출력 크기\n",
    "    output_dim = 1\n",
    "    torch_model = GCN(input_dim, graph_conv_layers, output_dim, dropout).to(device)\n",
    "    loss = nn.MSELoss()\n",
    "    # DeepChem 옵티마이저 사용\n",
    "    dc_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "    # DeepChem의 TorchModel로 래핑\n",
    "    try:\n",
    "        model = TorchModel(torch_model, loss=loss, optimizer=dc_optimizer, batch_size=batch_size, device=device)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(train_dataset, nb_epoch=100)\n",
    "\n",
    "        # 평가\n",
    "        metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "        train_score = model.evaluate(train_dataset, [metric], transformers)\n",
    "        valid_score = model.evaluate(valid_dataset, [metric], transformers)\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            'graph_conv_layers': graph_conv_layers,\n",
    "            'dense_layer_size': dense_layer_size,\n",
    "            'dropout': dropout,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'train_r2_score': train_score.get('pearson_r2_score', None),\n",
    "            'valid_r2_score': valid_score.get('pearson_r2_score', None)\n",
    "        })\n",
    "\n",
    "        print(f\"Train R2 Score: {train_score.get('pearson_r2_score', 'N/A')}, Validation R2 Score: {valid_score.get('pearson_r2_score', 'N/A')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과가 있는 경우만 저장 및 출력\n",
    "if not results_df.empty:\n",
    "    results_df = results_df.sort_values(by='valid_r2_score', ascending=False)\n",
    "    results_df.to_csv(\"gridsearch_results_pytorch.csv\", index=False)\n",
    "    print(\"\\nTop Results:\")\n",
    "    print(results_df.head())\n",
    "else:\n",
    "    print(\"No valid results collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd1cc4e4-2722-4e1e-882d-b9373929f244",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dc_optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTorchModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, loss=loss, optimizer=dc_optimizer, batch_size=batch_size\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_dataset, nb_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'loss'"
     ]
    }
   ],
   "source": [
    "dc_optimizer = Adam(learning_rate=learning_rate)\n",
    "model = TorchModel(torch_model,loss = 0.0, device=device) #, loss=loss, optimizer=dc_optimizer, batch_size=batch_size\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06dcad00-ab99-47ce-9c8c-9119cce54837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "\n",
    "# GPU 메모리를 최대한 활용하도록 설정\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], False)  # 동적 메모리 할당 비활성화\n",
    "        print(\"GPU set to use maximum memory\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"RuntimeError: {e}\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "422ea6aa-f2ee-4577-bacb-2e7208b23466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f919c-0163-432a-9cf9-4de608a6f881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search Progress:   0%|                                                                     | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running combination 1/36:\n",
      "graph_conv_layers: [64, 64], dense_layer_size: 128, dropout: 0.2, learning_rate: 0.001, batch_size: 256\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 목록 정의\n",
    "param_grid = {\n",
    "    'graph_conv_layers': [[64, 64], [128, 128], [64, 128, 64]],\n",
    "    'dense_layer_size': [128, 256],\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'learning_rate': [1e-3, 5e-4, 1e-4],\n",
    "    'batch_size': [256]  # GPU 메모리 상황에 따라 다양한 배치 크기를 실험\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "results = []\n",
    "\n",
    "# 하이퍼파라미터 조합 반복\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "combinations = list(product(\n",
    "    param_grid['graph_conv_layers'],\n",
    "    param_grid['dense_layer_size'],\n",
    "    param_grid['dropout'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['batch_size']\n",
    "))\n",
    "\n",
    "for i, (graph_conv_layers, dense_layer_size, dropout, learning_rate, batch_size) in enumerate(tqdm(combinations, desc=\"Grid Search Progress\")):\n",
    "    \n",
    "    print(f\"\\nRunning combination {i+1}/{len(combinations)}:\")\n",
    "    print(f\"graph_conv_layers: {graph_conv_layers}, dense_layer_size: {dense_layer_size}, dropout: {dropout}, learning_rate: {learning_rate}, batch_size: {batch_size}\")\n",
    "    \n",
    "    # 모델 초기화\n",
    "    with tf.device('/GPU:0'):  # 명시적으로 GPU 사용 설정\n",
    "        model = dc.models.GCNModel(\n",
    "            n_tasks=1,\n",
    "            graph_conv_layers=graph_conv_layers,\n",
    "            dense_layer_size=dense_layer_size,\n",
    "            dropout=dropout,\n",
    "            mode='regression',\n",
    "            learning_rate=learning_rate,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    # 모델 학습\n",
    "    try:\n",
    "        with tf.device('/GPU:0'):\n",
    "            model.fit(train_dataset, nb_epoch=100)\n",
    "\n",
    "        # 평가\n",
    "        train_score = model.evaluate(train_dataset, [dc.metrics.Metric(dc.metrics.pearson_r2_score)])\n",
    "        valid_score = model.evaluate(valid_dataset, [dc.metrics.Metric(dc.metrics.pearson_r2_score)])\n",
    "\n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            'graph_conv_layers': graph_conv_layers,\n",
    "            'dense_layer_size': dense_layer_size,\n",
    "            'dropout': dropout,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'train_r2_score': train_score['pearson_r2_score'],\n",
    "            'valid_r2_score': valid_score['pearson_r2_score']\n",
    "        })\n",
    "\n",
    "        print(f\"Train R2 Score: {train_score['pearson_r2_score']}, Validation R2 Score: {valid_score['pearson_r2_score']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# 결과 출력 및 저장\n",
    "results_df = results_df.sort_values(by='valid_r2_score', ascending=False)\n",
    "results_df.to_csv(\"gridsearch_results.csv\", index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\nTop Results:\")\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee982d9a-a5a7-401a-9fb6-4d54d846c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'pearson_r2_score': 0.8728071088137395}\n",
      "Test set score: {'pearson_r2_score': 0.7761037587217018}\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric]))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a35b1fe-f187-4f38-b6b0-7a41303983ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: {'pearson_r2_score': 0.8320443628967614}\n",
      "Validation score: {'pearson_r2_score': 0.802325296546151}\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 / GPT 파라미터 버전\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "train_score = model.evaluate(train_dataset, [metric])\n",
    "valid_score = model.evaluate(valid_dataset, [metric])\n",
    "\n",
    "print(\"Train score:\", train_score)\n",
    "print(\"Validation score:\", valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3ab43f3-71ff-4384-8ee9-80a1eb9298d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 Score: 0.735293292904228\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Test 데이터셋에 대한 예측값 추론\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "# 2. 실제 y값 (test_dataset.y) 과 비교하여 R2 스코어 계산\n",
    "test_r2 = r2_score(test_dataset.y, y_pred)\n",
    "\n",
    "print(\"Test R2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab73bc82-aba1-495d-a59b-576ff82573a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 Score: 0.7949052245292128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1. Test 데이터셋에 대한 예측값 추론\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "# 2. 실제 y값 (test_dataset.y) 과 비교하여 R2 스코어 계산\n",
    "test_r2 = r2_score(test_dataset.y, y_pred)\n",
    "\n",
    "print(\"Test R2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3971682-2f05-4f31-b250-c86f4a531b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 후\n",
    "model.save_checkpoint(model_dir=\"./Aquasol\")  # 원하는 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "913b0cb0-59c2-438c-b4f9-b2f72543ec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepchem.models.torch_models.gcn.GCNModel at 0x1d6a1a96760>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e3696-b523-4726-999c-4ec8039493eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchem",
   "language": "python",
   "name": "deepchem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
